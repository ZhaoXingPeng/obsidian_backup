{
	"nodes":[
		{"id":"4dae2631335bd27e","type":"group","x":1020,"y":-500,"width":680,"height":1920,"label":"Triple GAN架构"},
		{"id":"163be0e9298a03de","type":"group","x":-1160,"y":-500,"width":650,"height":1740,"label":"基础GAN设计"},
		{"id":"5dc76892639ef233","type":"text","text":"# GAN","x":0,"y":-780,"width":140,"height":60,"color":"1"},
		{"id":"71232a5c65347fe4","type":"file","file":"图片/Pasted image 20241024200138.png","x":240,"y":-480,"width":640,"height":250},
		{"id":"24d3b27eb840ead0","type":"file","file":"图片/Pasted image 20241024194654.png","x":-360,"y":-480,"width":400,"height":250},
		{"id":"b424e4c8c9b9a19a","type":"text","text":"## 基础GAN设计\n1. **生成器（Generator，图中的“生成器 (G)”）**：\n    - 生成器的任务是根据输入的随机噪声（Random Vector）生成假图片。你可以把它想象成一个伪造者，它想制作假钞票来欺骗警察。生成器不断学习如何生成看起来越来越真实的图像。\n2. **判别器（Discriminator，图中的“判别器 (D)”）**：\n    - 判别器的任务是区分图片是真实的还是生成的。它就像一名警察，要判断钱是真是假。判别器会接收真实图片（从训练数据集中获取）和生成器生成的假图片，并给出一个判断结果：真假。\n**GAN的训练过程**：\n- **生成对抗**：生成器和判别器在不断“对抗”中互相提升能力。\n    - 生成器试图欺骗判别器，生成更真实的图片。\n    - 判别器则试图区分真实图片和假图片，判断得更准确。\n- **优化目标**：\n    - 生成器的目标是让判别器判断生成的图片为“真实”（即判别器被欺骗）。\n    - 判别器的目标是提高区分真假图片的准确性。","x":-1140,"y":-480,"width":610,"height":520,"color":"4"},
		{"id":"d11b449f5d39e298","type":"text","text":"### 数据集设置\n在训练集中，模型使用了**半监督学习**的设置，即仅有一部分训练样本带有标签，其余样本不带标签：\n- **有标签数据**：训练集中的10%数据（按每类样本比例选取）被标记为有标签数据，用于指导模型的监督学习。这些数据传递给模型中的**生成器（G）**和**判别器（D）**，作为分类器和生成器的参考。\n- **无标签数据**：剩余的90%数据作为无标签数据（即未标注数据），仅传递给**分类器（C）**进行伪标签生成，分类器将这些无标签数据作为输入，生成伪标签供模型训练使用。\n在论文中，训练过程利用了10%的有标签数据和90%的无标签数据，有标签数据用于生成器、分类器和判别器的对抗训练，而无标签数据则通过分类器生成伪标签，随后用于判别器的训练。通过这种设置，C-TGAN 模型在仅有少量标签数据的情况下，能够有效利用大量未标注数据，提高模型的分类准确性和鲁棒性。\n","x":-20,"y":1120,"width":800,"height":320,"color":"4"},
		{"id":"3fd7c8ab51cddd6b","type":"text","text":"### 损失函数设计\n### 1. **判别器（D）的损失函数**\n\n- 判别器的损失函数 $D_{\\text{loss}}$​ 基于 Triple-GAN 的对抗损失进行设计。判别器接收三类数据-标签对：真实数据-真实标签对、伪标签-真实数据对（由分类器生成）、伪造数据-伪标签对（由生成器生成）。\n- 判别器的目标是区分这些数据-标签对是否为真实分布的数据对，通过最大化来自真实分布的数据对的预测概率，最小化来自伪造数据对的预测概率。\n- 判别器损失的公式如下： $D_{\\text{loss}} = \\frac{1}{m_l} \\sum_{(x_l, y_l)} \\log D(x_l, y_l) + \\frac{\\alpha}{m_c} \\sum_{(x_c, y_c)} \\log(1 - D(x_c, y_c)) + \\frac{1 - \\alpha}{m_g} \\sum_{(x_g, y_g)} \\log(1 - D(x_g, y_g))$其中 $m_l$、$m_c$和 $m_g$分别表示每一批次中真实数据、分类器生成的伪标签对和生成器生成的伪数据对的数量。常数 $\\alpha$ 控制不同数据对在损失中的权重。\n### 2. **生成器（G）的损失函数**\n- 生成器的损失函数 $G_{\\text{loss}}$ 也基于 Triple-GAN 的对抗损失设计，目标是让判别器将生成的数据样本判为“真实”。\n- 生成器的损失只依赖于伪数据对的分布，其公式如下： $G_{\\text{loss}} = \\frac{1 - \\alpha}{m_g} \\sum_{(x_g, y_g)} \\log(1 - D(x_g, y_g))$\n- 生成器通过最小化该损失，尽力生成能够“骗过”判别器的数据样本，以提高生成数据的质量。\n### 3. **分类器（C）的损失函数**\n- 分类器的损失函数 $C_{\\text{loss}}$综合了多项损失项，包括标准的监督损失、伪标签生成损失以及与 Mixup 数据增强相关的损失项。\n- 分类器损失公式如下：$C_{\\text{loss}} = \\sigma \\cdot \\text{lossc} + R_l + \\mu R_g + R_m$\n    - **第一项 $\\sigma \\cdot \\text{lossc}$**：监督损失，确保分类器对真实数据的分类结果符合实际标签分布。\n    - **第二项 $R_l$**：标准监督损失，确保分类器在真实数据上达到全局最优。\n    - **第三项$\\mu R_g$**：伪标签判别损失，优化分类器在生成数据上的伪标签预测。\n    - **第四项 $R_m$**：Mixup 损失，通过生成的 Mixup 数据样本提高分类器的鲁棒性和泛化能力。","x":-20,"y":300,"width":800,"height":800,"color":"4"},
		{"id":"988521bfad787a82","type":"text","text":"### 1. **C-TGAN 的结构改进**\n- **连接结构（Connection Structure）**：为了更有效地传递标签信息，C-TGAN 引入了一个连接结构，将生成器和判别器中的一维标签向量与三维特征矩阵相连。这个连接结构使用全连接层，将一维标签信息扩展为三维矩阵，再与特征矩阵拼接，确保每层卷积操作中包含标签信息。这样可以帮助生成器和判别器更好地捕获标签相关特征。\n- **Mixup 数据增强策略**：在分类器中应用了 Mixup 数据增强策略，即通过线性插值生成新的样本和标签组合。Mixup 生成的数据样本可以提高分类器的鲁棒性，减少对伪标签的敏感性，且在训练时添加了相关的损失项来优化分类器。\n- **举例**：\n- 假设我们有两个真实数据样本 $(x_1, y_1)$ 和 $(x_2, y_2)$，其中 $x_1$ 和 $x_2$分别代表“坐下”和“站起”动作的微多普勒光谱，标签 $y_1$​ 和 $y_2$分别为 [1, 0, 0, 0, 0, 0] 和 [0, 1, 0, 0, 0, 0]。\n- **生成新的 Mixup 样本**：随机采样一个系数 $\\beta$，假设 $\\beta = 0.7$。Mixup 会生成新的样本 $x_m$​ 和标签 $y_m$，定义为： $x_m = 0.7 \\cdot x_1 + 0.3 \\cdot x_2$$y_m = 0.7 \\cdot y_1 + 0.3 \\cdot y_2 = [0.7, 0.3, 0, 0, 0, 0]$\n    - 这样得到的 $x_m$是一个介于“坐下”和“站起”之间的动作光谱，而 $y_m$则是对应的线性标签。","x":-20,"y":-140,"width":800,"height":420,"color":"4"},
		{"id":"2fcc767cf2ed710f","type":"text","text":"## 损失函数设计\n二元交叉熵损失函数（Binary Cross Entropy Loss, BCELoss）\n![[Pasted image 20241024195426.png]]\n- **生成器的损失函数**：\n    - 生成器的目标是让判别器对生成的假图像输出“真实”的标签（即标签为1）。因此，生成器的损失函数计算了判别器对生成图像的输出与标签“真实”的交叉熵损失。\n    - 代码中这一部分的实现是：\n        `g_loss = adversarial_loss(discriminator(gen_imgs), valid)`\n        这里 `valid` 标签的值全为1，代表生成器希望判别器认为这些生成的图像是“真实的”。\n- **判别器的损失函数**：\n    - 判别器的目标是对真实图像的输出尽量接近标签“真实”（1），对生成图像的输出尽量接近标签“虚假”（0）。因此，判别器的损失函数分为两个部分：\n        1. 真实图像的损失：计算判别器对真实图像输出和真实标签之间的损失。\n        2. 假图像的损失：计算判别器对生成的假图像输出和假标签之间的损失。\n    - 判别器的总损失是这两部分损失的平均值：\n        `real_loss = adversarial_loss(discriminator(real_imgs), valid) fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake) d_loss = (real_loss + fake_loss) / 2`\n        这里 `real_imgs` 是来自MNIST数据集的真实图像，`gen_imgs` 是生成器生成的假图像，`valid` 是标签1，`fake` 是标签0。","x":-1140,"y":60,"width":610,"height":920,"color":"4"},
		{"id":"f22d5f96c7188fcf","type":"file","file":"图片/Pasted image 20241029152505.png","x":-1080,"y":1000,"width":454,"height":217},
		{"id":"fa3dba6594528be0","type":"text","text":"### 图中的三大部分：\n\n1. **生成器（G）**：\n    - **作用**：生成器的任务是从随机噪声（Zg​）中生成样本，目的是使得生成样本看起来与真实样本一样。\n    - **输入和输出**：\n        - 输入：随机噪声 Zg∼pz(Z) 和类别标签 Yg∼p(Y)。\n        - 输出：生成样本 Xg，与标签 Yg配对，即生成的样本对 (Xg,Yg)。\n2. **判别器（D）**：\n    - **作用**：判别器用于区分输入样本是从真实数据分布中抽样的还是由生成器生成的。它不仅需要判断输入的样本（X）是真实还是生成的，还需要判断输入的标签是否合理。\n    - **输入**：\n        - 三种输入：\n            - 真实样本对 $(X_l, Y_l) \\sim p(X, Y)$：这是带有标签的真实数据样本。\n            - 分类器生成的样本对 $(X_c, Y_c) \\sim p_c(X, Y)$：通过分类器将无标签样本配对一个类别标签。\n            - 生成器生成的样本对$(X_g, Y_g) \\sim p_g(X, Y)$：由生成器生成的图像和对应标签。\n    - **输出**：\n        - 判别器对输入样本输出两个值：“真实/生成”（A/R），以及标签的有效性（A）。\n3. **分类器（C）**：\n    \n    - **作用**：分类器用于给无标签的输入样本分配一个标签，同时希望提高整个模型的稳定性。分类器的加入使得 GAN 模型不仅能够生成逼真的样本，还能使生成的样本具有明确的类别信息。\n    - **输入和输出**：\n        - 输入：来自无标签数据的样本 $X_c \\sim p(X)$，以及带标签的数据对 $(X_l, Y_l) \\sim p(X, Y)$ 。\n        - 输出：对输入样本进行分类，并使用交叉熵损失（CE）训练。","x":1040,"y":-480,"width":640,"height":820,"color":"4"},
		{"id":"6d498e68648b1496","type":"text","text":"假设我们有真实数据集 MNIST，包含从 0 到 9 的手写数字。Triple GAN 的训练步骤如下：\n1. **训练生成器**：\n    - 随机生成一个噪声 Zg​ 和一个目标标签 Yg​，例如 $Y_g = 2$。\n    - 生成器通过网络生成一个数字 \"2\" 的图像 Xg，输出为样本对 $(X_g, Y_g)$。\n    - 目标是让判别器对 $(X_g, Y_g)$ 的输出结果为“真实”，即生成器希望欺骗判别器，使判别器认为生成的样本是真实的。\n    - 生成器通过最小化与真实标签的损失来优化自己。\n2. **训练分类器**：\n    - 对于无标签数据样本 Xc，分类器预测它的标签 Yc。\n    - 分类器的训练目标是让其能够正确地预测无标签样本的类别。\n    - 例如，分类器接收到一个无标签的手写数字图像，它需要给这个图像分配一个合适的标签，例如 \"3\"。\n    - 通过交叉熵损失来优化分类器的参数，使其能够尽可能准确地预测样本的类别。\n3. **训练判别器**：\n    - 判别器接收三类输入：\n        1. 真实样本对$(X_l, Y_l)$：例如真实的数字 \"7\" 和标签 \"7\"。\n        2. 分类器生成的样本对$(X_c, Y_c)$：分类器对无标签样本的预测，例如无标签图像被分配为 \"3\"。\n        3. 生成器生成的样本对$(X_g, Y_g)$：生成器生成的数字 \"5\" 和标签 \"5\"。\n    - 判别器需要判断这些样本是真实还是生成的，目的是最大化对真实样本的判断为“真实”，以及最大化对生成样本的判断为“虚假”。\n    - 判别器通过最小化对真实样本和生成样本的错误判断来优化自己。\n### 生成和判别的博弈\n- 在原始 GAN 中，生成器和判别器之间是单一的对抗关系。\n- 在 Triple GAN 中，生成器、判别器和分类器之间形成了三方博弈：\n    - 生成器希望生成逼真的样本，使判别器和分类器都无法区分。\n    - 判别器需要区分输入的样本是来自真实数据还是由生成器生成的。\n    - 分类器希望提高对真实数据和生成数据的分类能力。\nTriple GAN 中有三方的相互博弈，最终希望达到以下效果：\n- **生成器（G）**：能够生成逼真的手写数字图像，并且能够生成具有特定标签的样本，例如生成数字 \"5\"。\n- **分类器（C）**：能够正确地预测无标签的输入图像的类别。\n- **判别器（D）**：能够有效地区分输入样本是真实的还是生成的，并判断标签是否合理。","x":1040,"y":360,"width":640,"height":1040,"color":"4"}
	],
	"edges":[
		{"id":"89f20ac7e31759b7","fromNode":"24d3b27eb840ead0","fromSide":"left","toNode":"b424e4c8c9b9a19a","toSide":"right"},
		{"id":"df80f34631156749","fromNode":"24d3b27eb840ead0","fromSide":"left","toNode":"2fcc767cf2ed710f","toSide":"right"},
		{"id":"3d8f709fee5a9896","fromNode":"71232a5c65347fe4","fromSide":"right","toNode":"fa3dba6594528be0","toSide":"left"},
		{"id":"56bb2a237e00c726","fromNode":"71232a5c65347fe4","fromSide":"right","toNode":"6d498e68648b1496","toSide":"left"},
		{"id":"9bb75a974c7b3a5a","fromNode":"5dc76892639ef233","fromSide":"bottom","toNode":"24d3b27eb840ead0","toSide":"top"},
		{"id":"a07f915166a84199","fromNode":"5dc76892639ef233","fromSide":"bottom","toNode":"71232a5c65347fe4","toSide":"top"},
		{"id":"5d83ad0304ef1869","fromNode":"71232a5c65347fe4","fromSide":"bottom","toNode":"988521bfad787a82","toSide":"top"},
		{"id":"97106fa5dda18d9c","fromNode":"988521bfad787a82","fromSide":"bottom","toNode":"3fd7c8ab51cddd6b","toSide":"top"},
		{"id":"d0db6571e21aaed3","fromNode":"3fd7c8ab51cddd6b","fromSide":"bottom","toNode":"d11b449f5d39e298","toSide":"top"}
	]
}