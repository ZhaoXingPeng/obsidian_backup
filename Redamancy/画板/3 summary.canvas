{
	"nodes":[
		{"id":"742904ad23150ab1","type":"text","text":"## 数据处理过程\n首先，雷达采集到的一维（1D）回波数据是时间序列形式的，这些数据被记录为`slow time`（慢时间）和`fast time`（快时间）信号。`fast time`表示雷达信号在一个脉冲内的采样，用于描述目标的距离信息；而`slow time`则对应多个脉冲的采样时间序列，描述的是目标的速度信息。通过将这些一维数据按照`slow time`和`fast time`的关系排列形成一个二维数据矩阵，其中行表示`fast time`，列表示`slow time`。\n\n接下来，论文采用二维傅里叶变换（2D FFT）来将这个二维数据矩阵从时域转换到频域，生成距离-多普勒图像。在这个图像中，横轴代表距离（由`fast time`信息决定），纵轴代表多普勒频移（由`slow time`信息决定），这可以反映出目标的运动速度信息。\n\n然后，为了获得更直观的微多普勒特征谱图，论文会对距离-多普勒图像进行能量累积处理。具体来说，通过沿着距离轴（`fast time`方向）叠加能量，可以生成一个新的图像，这个图像的横轴表示时间（帧数），纵轴表示微多普勒频谱的强度。这种微多普勒特征谱图捕捉了目标在运动过程中的细节变化特征。\n\n到此为止，三篇论文的数据处理步骤完成了从雷达回波信号到微多普勒特征谱图的转化。随后，这些谱图作为输入数据，后续问题则转化成计算机视觉（CV）问题，通过深度学习方法进行进一步的人体姿态估计等任务处理。","x":-240,"y":-280,"width":540,"height":620,"color":"5"},
		{"id":"699d670f996bb36a","type":"text","text":"## SCRP-Radar\n首先，将微多普勒谱图输入一个基础神经网络（文中使用的是HRNet），生成特征图。然后，通过一个全连接层（每个关节点使用不同的全连接参数），得到17个关节点的特征嵌入向量。本文的创新点在于其采用了一种新的‘空间感知坐标表示’方法。传统的方法通常是通过热力图直接回归获取x、y坐标，这是一个回归问题；然而，文中提出的方法将x和y坐标的预测分别转化为两个分类问题。\n‘空间感知坐标表示’具体指的是SimCC (Simultaneous Coordinate Classification) 方法，它通过将每个关节点的x和y坐标预测分别看作两个独立的分类任务来解决人体姿态估计问题。首先，沿x轴和y轴分别将空间区域划分为多个离散的区间，每个区间代表一个分类标签。接着，通过神经网络对每个区间的概率进行预测，得到关于x和y坐标的概率分布向量。这样的设计可以更好地捕捉微小位置变化的细节信息，增强模型的精度与鲁棒性。\n在获得x和y坐标的概率向量后，我们需要解码出每个关节点的坐标。解码的方式是通过对这些概率向量进行加权平均计算，得出每个关节点的x和y坐标预测值。具体而言，将每个分类区间的中心坐标与其概率相乘并求和，得到最终的坐标预测。这个过程对每个关节点的x和y坐标分别进行，最终得到17组精确的关节点坐标预测值。\n因此，文章的贡献主要体现在提出一种更为准确和鲁棒的方法来处理雷达数据中的关节点提取问题，而不是完整的人体姿态估计流程。这也就是说，文章解决的是HPE前期的关键步骤，而不是整个HPE任务的终结。","x":-840,"y":420,"width":500,"height":700,"color":"5"},
		{"id":"49b305b146bb65bd","type":"text","text":"## 相关工作\n这三篇论文在前期工作中均讨论了基于摄像头、毫米波雷达、多输入多输出（MIMO）雷达和频率调制连续波（FMCW）雷达的姿态估计方法。它们的共同点在于利用雷达信号的时频特征（特别是微多普勒特征）来捕捉人体运动并重建姿态。尽管不同的方法使用了不同的雷达类型和深度学习框架，但它们都旨在解决在复杂环境和遮挡情况下的人体姿态估计问题，同时减少对隐私的侵扰。","x":-740,"y":-140,"width":400,"height":340,"color":"5"},
		{"id":"c53308f58ed356f4","type":"text","text":"## Three-Dimensional HPE","x":1020,"y":420,"width":520,"height":700,"color":"5"},
		{"id":"d8108064d3fa92e2","type":"text","text":"## MDST","x":-240,"y":420,"width":540,"height":700,"color":"5"},
		{"id":"a43ff52b9207c3de","type":"file","file":"图片/Pasted image 20240911185225.png","x":-240,"y":-460,"width":540,"height":156,"color":"5"},
		{"id":"a81a9131b7a7a7a7","x":-240,"y":1140,"width":540,"height":200,"type":"file","file":"图片/Pasted image 20240911185545.png"},
		{"id":"1e9fce37e27d3ef5","type":"text","text":"## MD-Pose","x":420,"y":420,"width":520,"height":700,"color":"5"},
		{"id":"7c96703dd0690631","x":-740,"y":-500,"width":400,"height":300,"color":"4","type":"text","text":"**Human Pose Estimation**（人体姿态估计）是一种计算机视觉任务，旨在通过图像或视频来检测和定位人体的关节（如头部、肩膀、肘部、膝盖等）的位置。它的目标是输出人体骨架的结构，即人体关键点（keypoints）的坐标，通常以二维或三维形式表示。\n**人体动作识别**（Human Action Recognition, HAR）是计算机视觉和机器学习领域的一项任务，旨在通过分析图像序列或视频数据来识别和分类人类的动作或行为。"},
		{"id":"1f0ed0c7359d5131","x":-240,"y":1360,"width":540,"height":560,"color":"4","type":"text","text":"首先，Transformer 最早应用于序列到序列 (seq2seq) 任务，例如机器翻译。其主要特点是通过自注意力机制来捕捉序列中不同位置的全局依赖关系而无需像 RNN 或 CNN 那样引入递归或卷积操作​。\n\n后来，Vision Transformer (ViT) 被提出并应用于图像分类任务。\nViT 的核心思想是将输入图像划分为多个固定大小的图像块（patch），ViT在输入序列中添加一个可学习的分类标记（[class] token）。每个 patch 被展平后通过线性投影映射到一个固定维度的向量空间，形成一系列的 patch embeddings。与自然语言处理中的词嵌入类似，这些 patch embeddings 再加上位置编码（position embeddings），共同作为 Transformer 的输入序列。\n\n然而，ViT 也存在一些问题，比如在小数据集上表现较差，因为其模型结构缺乏对局部特征的专门处理。Swin Transformer 在 ViT 的基础上引入了“窗口”这一概念，将自注意力操作限制在局部的非重叠窗口内，从而保留了局部性。同时，窗口可以通过“滑动”机制进行移动，这使得 Swin Transformer 能够逐步建立跨窗口的连接，扩大感受野。此外，Swin Transformer 通过 Patch Merging 机制逐层减少 token 的数量，使得计算效率更高​(Vision Transformers (Vi…)。相比之下，Swin Transformer 在保留全局信息的同时，更好地捕捉了局部特征。"},
		{"id":"34e8042c4bd9420b","type":"file","file":"图片/Pasted image 20240911185305.png","x":-840,"y":1160,"width":500,"height":124,"color":"5"}
	],
	"edges":[
		{"id":"7bc207238e482f74","fromNode":"49b305b146bb65bd","fromSide":"right","toNode":"742904ad23150ab1","toSide":"left","color":"5"},
		{"id":"ff5a3a9200bb63fa","fromNode":"742904ad23150ab1","fromSide":"bottom","toNode":"699d670f996bb36a","toSide":"top","color":"5"},
		{"id":"81843c8b4bb739af","fromNode":"742904ad23150ab1","fromSide":"bottom","toNode":"d8108064d3fa92e2","toSide":"top","color":"5"},
		{"id":"367df482050a7104","fromNode":"742904ad23150ab1","fromSide":"bottom","toNode":"1e9fce37e27d3ef5","toSide":"top","color":"5"},
		{"id":"c4be2c8a4e4e4623","fromNode":"742904ad23150ab1","fromSide":"bottom","toNode":"c53308f58ed356f4","toSide":"top","color":"5"},
		{"id":"c8f333054a8741de","fromNode":"a81a9131b7a7a7a7","fromSide":"bottom","toNode":"1f0ed0c7359d5131","toSide":"top"},
		{"id":"701f1fbd49c639fe","fromNode":"a81a9131b7a7a7a7","fromSide":"top","toNode":"d8108064d3fa92e2","toSide":"bottom"},
		{"id":"2d5a2256a81bbca3","fromNode":"34e8042c4bd9420b","fromSide":"top","toNode":"699d670f996bb36a","toSide":"bottom"}
	]
}