{
	"nodes":[
		{"id":"5b9636c37da16b79","type":"group","x":-1520,"y":-1160,"width":960,"height":4009,"color":"2","label":"Human Activity Recognition"},
		{"id":"4ee0086a411d929a","type":"text","text":"Transformer基础架构用于视觉任务的发展历程","x":-120,"y":-1169,"width":410,"height":60,"color":"3"},
		{"id":"aa8df530b002ccf2","type":"text","text":"**初期探索（2017-2019）**：最初，Transformer主要应用于自然语言处理（NLP）领域，2017年的论文《Attention is All You Need》提出了Transformer架构","x":-120,"y":-1069,"width":410,"height":120,"color":"3"},
		{"id":"0bd9e40011791242","type":"text","text":"**ViT的提出（2020）**：谷歌在2020年发布的**论文**: [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/abs/2010.11929)中，提出了Vision Transformer（ViT），首次将Transformer直接应用于原始图像数据。ViT通过将图像划分为补丁并将其视为序列数据，尤其是在大规模数据集上。","x":-120,"y":-909,"width":410,"height":200,"color":"3"},
		{"id":"0e801b60be78dc4e","type":"text","text":"**扩展与优化（2021-2022）**：随着ViT的成功，研究者们开始对Transformer进行改进，提出了多种变体，如DeiT（Data-efficient Image Transformers），通过引入知识蒸馏技术提高小数据集上的表现。同时，也有研究关注计算效率和模型压缩，提出了如Swin Transformer的局部窗口自注意力机制。**DeiT（Data-efficient Image Transformers）** **论文**: [Training Data-efficient Image Transformers & Distillation through Attention](https://arxiv.org/abs/2012.12877)   **Swin Transformer** **论文**: [Swin Transformer: Hierarchical Vision Transformer using Shifted Windows](https://arxiv.org/abs/2103.14030)","x":-120,"y":-680,"width":410,"height":320,"color":"3"},
		{"id":"a6afded3c1bcf43b","type":"text","text":"**多模态学习（2022-至今）**：Transformer在视觉任务中的成功推动了多模态学习的发展，例如结合文本和图像的模型（如CLIP和ALIGN）。这些模型利用Transformer架构同时处理不同模态的数据，提升了跨领域的任务表现。","x":-120,"y":-320,"width":410,"height":160,"color":"3"},
		{"id":"062f859f722c5e72","type":"text","text":"**摘要**: 谷歌在这篇论文中首次提出了Vision Transformer（ViT），将Transformer架构直接应用于图像数据。作者将图像分成固定大小的补丁（如16x16），并将这些补丁展平作为序列输入到Transformer中。实验表明，ViT在大规模数据集（如ImageNet）上表现优异，甚至超过了传统卷积神经网络（CNN）。","x":360,"y":-899,"width":540,"height":149,"color":"3"},
		{"id":"35c8e7cf83a5c5a8","type":"text","text":"DeiT通过引入知识蒸馏技术，提升了ViT在小数据集上的性能。论文中，作者提出了使用一个较小的卷积神经网络作为教师模型，帮助ViT进行训练，显著提高了小样本学习的效果。","x":360,"y":-730,"width":540,"height":100,"color":"3"},
		{"id":"c5952d581e682572","type":"text","text":"**摘要**: Swin Transformer提出了一种局部窗口自注意力机制，通过在不同层次上实现逐层的自注意力，改进了计算效率。该模型适用于各种视觉任务，如目标检测和图像分割，展现了出色的性能。","x":360,"y":-610,"width":540,"height":100,"color":"3"},
		{"id":"4082ae1a597e9bfa","type":"text","text":"知识蒸馏是一种机器学习技术，用于提高模型的表现。简单来说，它的核心思想是用一个大、复杂的模型（称为“教师”模型”）来教一个小、简单的模型（称为“学生”模型）。教师模型在大量数据上训练得很好，而学生模型则通过模仿教师模型的输出，学习到有用的特征和信息。","x":940,"y":-730,"width":320,"height":220,"color":"3"},
		{"id":"7851cf57a7271a20","type":"text","text":"人体姿态估计（HPE）","x":-1040,"y":-1320,"width":240,"height":60,"color":"3"},
		{"id":"58abfdf511c6185c","type":"text","text":"人体行为识别（HAR）","x":-740,"y":-1320,"width":240,"height":60,"color":"3"},
		{"id":"121ea5b683704aa7","type":"text","text":"# Point Cloud\n\n1. **英文标题**: *Cross Vision-RF Gait Re-identification with Low-cost RGB-D Cameras and mmWave Radars*  \n   **中文标题**: 低成本RGB-D摄像机和毫米波雷达的跨视觉-RF步态再识别  \n   - **数据形式**: 毫米波雷达生成的RF信号和RGB-D摄像机捕获的深度图像数据。  \n   - **结果**: 系统在摄像头允许和限制区域中都能实现跨模态身份跟踪，并在复杂的多人场景中表现优异。  \n   - **使用网络及创新点**: 使用了结合毫米波信号和RGB-D图像数据的跨模态神经网络，创新点是提出跨模态步态再识别架构，能够处理多目标场景中的识别问题【6†source】【7†source】。\n\n2. **英文标题**: *Rapture: A Lightweight Gesture Recognition System from mmWave Radar Sparse Point Clouds*  \n   **中文标题**: Rapture：基于毫米波雷达稀疏点云的轻量化手势识别系统  \n   - **数据形式**: 毫米波雷达生成的稀疏点云数据。  \n   - **结果**: 在低计算资源的环境下，系统可以高效、准确地进行手势识别，特别适用于移动设备和智能家居。  \n   - **使用网络及创新点**: 使用轻量化卷积神经网络（CNN）处理毫米波稀疏点云，创新点在于系统简化了架构，适合在资源受限环境中实现实时手势识别。\n\n3. **英文标题**: *m-Activity: Accurate and Real-Time Human Activity Recognition Via Millimeter Wave Radar*  \n   **中文标题**: m-Activity：基于毫米波雷达的准确实时人体活动识别  \n   - **数据形式**: 使用毫米波雷达的活动信号数据，通过频率、时间和幅度变化反映人体活动。  \n   - **结果**: 实时准确地识别出人体的不同活动类型，特别是在复杂场景中保持高准确性。  \n   - **使用网络及创新点**: 采用了基于LSTM的时序数据处理网络，创新点在于利用LSTM处理毫米波信号的时序特征，提升了活动识别的实时性和准确性。\n\n4. **英文标题**: *Real-time Arm Gesture Recognition in Smart Home Scenarios via MillimeterWave Sensing*  \n   **中文标题**: 智能家居场景中的基于毫米波感知的实时手势识别  \n   - **数据形式**: 毫米波雷达捕捉手势动态数据，反映手势的移动轨迹。  \n   - **结果**: 系统能够在智能家居场景中实现无接触的手势控制，具有较高的实时性和准确性。  \n   - **使用网络及创新点**: 使用卷积神经网络（CNN），结合毫米波雷达的空间和时间特征进行手势识别。创新点在于融合了毫米波传感的动态信息与CNN的特征提取能力。\n\n5. **英文标题**: *RadHAR: Human Activity Recognition from Point Clouds Generated through a Millimeter-wave Radar*  \n   **中文标题**: RadHAR：通过毫米波雷达生成的点云进行人体活动识别  \n   - **数据形式**: 毫米波雷达生成的三维点云数据，反映了人体的三维空间活动。  \n   - **结果**: 在复杂的多人体活动场景中，系统能够高效识别人体活动，证明毫米波雷达在活动识别中的有效性。  \n   - **使用网络及创新点**: 使用基于3D卷积神经网络（3D-CNN）的架构，创新点在于利用毫米波生成的3D点云进行活动识别，适用于复杂的三维空间活动场景。","x":-1500,"y":-1140,"width":900,"height":889,"color":"4"},
		{"id":"b9b081a8467267a7","type":"text","text":"# Micro-Doppler\n- **《2022年——Attention-Based Dual-Stream Vision Transformer for Radar Gait Recognition》**\n    \n    - **使用的特征**：该论文处理毫米波雷达生成的微多普勒信号和人体步态特征，通过雷达回波信号捕捉不同步态的微小差异。\n    - **数据形式**：微多普勒信号特征和雷达捕捉到的步态信息，以时间和频率的变化形式反映不同个体的步态模式。\n    - **结果**：通过结合视觉和雷达数据流，该系统实现了高精度的步态识别。\n    - **使用网络及创新点**：使用了基于注意力机制的双流视觉Transformer网络（Vision Transformer, ViT），其创新点在于结合雷达和视觉信息，同时通过注意力机制加强对不同步态模式的精确识别。\n- **《2021年——Human Motion Recognition With Limited Radar Micro-Doppler Signatures》**\n    \n    - **使用的特征**：该论文使用了雷达生成的有限微多普勒特征，这些特征反映了人体运动的速度和形态变化。\n    - **数据形式**：微多普勒信号，主要从人体的运动轨迹中提取。\n    - **结果**：该系统在有限的微多普勒特征条件下，依然能够准确识别人体运动，尤其在噪声较大的环境中表现出色。\n    - **使用网络及创新点**：采用了深度卷积神经网络（CNN）架构，创新点在于优化了在有限雷达数据下的特征提取和运动识别，提升了系统的鲁棒性和准确性。\n- **《2018年——Personnel Recognition and Gait Classification Based on Multistatic Micro-Doppler Signatures Using Deep Convolutional Neural Networks》**\n    \n    - **使用的特征**：该论文使用了多静态雷达的微多普勒特征，这些特征通过多角度捕捉人体运动的速度、频率和形态，反映了个体独特的步态和运动模式。\n    - **数据形式**：微多普勒特征，来源于多静态雷达系统生成的多视角数据。\n    - **结果**：该系统能够准确区分不同个体的步态，并进行人员识别，尤其适合复杂场景中的步态分类。\n    - **使用网络及创新点**：使用了深度卷积神经网络（CNN），其创新点在于结合多静态微多普勒数据，通过多角度特征的深度学习提高了步态分类的精度和泛化能力。","x":-1500,"y":489,"width":900,"height":700,"color":"4"},
		{"id":"a849c06cd9c575f2","type":"text","text":"# Domain Adaption\n- **《2022年——Unsupervised Learning for Human Sensing Using Radio Signals》**\n    \n    - **使用的特征**：处理的是雷达信号中的微多普勒特征，这些信号反映了人体运动产生的频率变化。\n    - **数据形式**：未标注的雷达信号数据。\n    - **结果**：该系统展示了在无监督学习模式下，通过雷达信号有效地感知和识别人类活动，解决了在缺乏标注数据的情况下的识别难题。\n    - **使用网络及创新点**：使用无监督学习网络，创新点在于使用自监督学习方法从雷达信号中提取有效特征，提升了人类活动感知的准确性。\n- **《2022年——Unsupervised Domain Adaptation across FMCW Radar Configurations Using Margin Disparity Discrepancy》**\n    \n    - **使用的特征**：FMCW（调频连续波）雷达生成的信号特征，主要用于反映人体运动的距离和速度。\n    - **数据形式**：FMCW雷达的配置数据，进行跨域适应。\n    - **结果**：该系统通过无监督的域适应技术，在不同FMCW雷达配置下保持了较好的手势识别效果，减少了雷达配置不同导致的性能差异。\n    - **使用网络及创新点**：使用了基于Margin Disparity Discrepancy（MDD）的无监督域适应网络，创新点在于跨配置的域适应，能够在不同雷达配置下保持稳定的性能。\n- **《2022年——mTransSee: Enabling Environment-Independent mmWave Sensing Based Gesture Recognition via Transfer Learning》**\n    \n    - **使用的特征**：毫米波雷达生成的手势信号，反映手势动作的动态变化。\n    - **数据形式**：不同环境下的毫米波雷达信号。\n    - **结果**：该系统通过迁移学习实现了环境无关的手势识别，能够在不同的物理环境中稳定地进行手势识别。\n    - **使用网络及创新点**：使用了迁移学习网络，创新点在于通过迁移学习解决不同环境下手势识别性能不稳定的问题。\n- **《2022年——Few-Shot User-Definable Radar-Based Hand Gesture Recognition at the Edge》**\n    \n    - **使用的特征**：雷达信号中捕捉到的手势特征。\n    - **数据形式**：少量标注的雷达手势数据。\n    - **结果**：该系统展示了在有限的训练样本下，能够通过少样本学习实现边缘设备上的高效手势识别。\n    - **使用网络及创新点**：使用少样本学习网络（Few-Shot Learning），创新点在于实现了边缘计算环境下用户可定义的手势识别。\n- **《2021年——Towards Domain-Independent and Real-Time Gesture Recognition Using mmWave Signal》**\n    \n    - **使用的特征**：毫米波信号生成的手势特征。\n    - **数据形式**：来自不同领域的毫米波手势信号数据。\n    - **结果**：通过域无关的手势识别，系统能够在实时环境中有效识别手势动作。\n    - **使用网络及创新点**：采用了域无关特征学习网络，创新点在于通过消除领域间的数据差异，实现了高效的手势识别。\n- **《2021年——Semisupervised Human Activity Recognition With Radar Micro-Doppler Signatures》**\n    \n    - **使用的特征**：雷达微多普勒特征，反映人体运动的速度和频率变化。\n    - **数据形式**：部分标注的雷达数据。\n    - **结果**：在半监督学习下，系统在少量标注数据和大量未标注数据的情况下，仍能有效识别人类活动。\n    - **使用网络及创新点**：使用半监督学习网络，创新点在于通过结合标注和未标注数据提升了模型的学习效率。\n- **《2021年——Supervised Domain Adaptation for Few-Shot Radar-Based Human Activity Recognition》**\n    \n    - **使用的特征**：雷达微多普勒特征，反映人体活动特征。\n    - **数据形式**：少量标注的雷达数据。\n    - **结果**：该系统通过少样本学习和监督域适应技术，解决了雷达人类活动识别中的跨域问题。\n    - **使用网络及创新点**：使用了少样本学习和监督域适应网络，创新点在于通过监督域适应提升了少样本情况下的跨领域识别能力。\n- **《2021年——Towards Cross-Environment Human Activity Recognition Based on Radar Without Source Data》**\n    \n    - **使用的特征**：跨环境的雷达微多普勒特征。\n    - **数据形式**：目标环境的雷达活动数据，源环境数据缺失。\n    - **结果**：该系统展示了在没有源环境数据的情况下，如何在目标环境中有效地进行活动识别。\n    - **使用网络及创新点**：使用了自监督和跨环境学习网络，创新点在于无需源环境数据，依然能够在新环境中准确识别活动。\n- **《2021年——Continual Learning of Micro-Doppler Signature-Based Human Activity Classification》**\n    \n    - **使用的特征**：雷达微多普勒特征，反映人体活动的时间和频率变化。\n    - **数据形式**：随时间变化的雷达活动数据。\n    - **结果**：系统能够在不断更新的数据流中持续学习，逐步提升人类活动识别的精度。\n    - **使用网络及创新点**：使用了持续学习网络（Continual Learning），创新点在于解决了随着新数据到来，模型如何持续更新学习的挑战，避免了遗忘问题。","x":-1500,"y":1229,"width":900,"height":1600,"color":"4"},
		{"id":"4c79d03743aad509","type":"text","text":"# RD Range-Doppler\n- **《2021年——RadarNet: Efficient Gesture Recognition Technique Utilizing a Miniature Radar Sensor》**\n    \n    - **使用的特征**：该论文使用的是由毫米波雷达生成的时频数据。毫米波雷达能够捕捉动态手势的微小变化，生成一系列反映时间和频率变化的信号。\n    - **数据形式**：信号数据通过特征提取方法生成时频特征，如多普勒频移、幅度变化等。这些特征用于手势识别。\n    - **主要创新点**：RadarNet通过利用高效的卷积神经网络架构，结合这些时频特征，实现了手势识别的实时性和高精度。\n- **《2016年——Interacting with Soli: Exploring Fine-Grained Dynamic Gesture Recognition in the Radio-Frequency Spectrum》**\n    \n    - **使用的特征**：这篇论文使用的是通过Soli雷达捕获的RF信号特征。Soli是一种专门设计用于捕捉细微手势的毫米波雷达，生成丰富的手势动态特征。\n    - **数据形式**：这些特征包括手势在RF频谱内的微小反射变化，结合了速度、加速度、多普勒效应等信号。\n    - **主要创新点**：Soli系统通过捕捉手指微小的动态动作，支持精细的动态手势识别，在无需接触的情况下实现了高精度的控制功能。\n- **《2015年——Short-Range FMCW Monopulse Radar for Hand-Gesture Sensing》**\n    \n    - **使用的特征**：该论文使用了FMCW（调频连续波）雷达捕捉的回波信号特征。FMCW雷达可以检测距离、速度和角度，生成能够反映手势运动的三维空间特征。\n    - **数据形式**：通过多普勒效应、时间延迟以及相位信息提取手势动作的精确特征。这些数据有助于短距离手势识别。\n    - **主要创新点**：该论文提出了FMCW Monopulse雷达在短距离手势识别中的应用，特别是通过提高角度和距离测量的精度，实现了手势识别的可靠性和快速响应。","x":-1500,"y":-191,"width":900,"height":640,"color":"4"}
	],
	"edges":[
		{"id":"f0569e1275f51f95","fromNode":"4ee0086a411d929a","fromSide":"bottom","toNode":"aa8df530b002ccf2","toSide":"top","color":"3"},
		{"id":"e2518474e7de7b3b","fromNode":"aa8df530b002ccf2","fromSide":"bottom","toNode":"0bd9e40011791242","toSide":"top","color":"3"},
		{"id":"97c8c5822f2bc4cb","fromNode":"0bd9e40011791242","fromSide":"bottom","toNode":"0e801b60be78dc4e","toSide":"top","color":"3"},
		{"id":"947c11fd257f7b8d","fromNode":"0e801b60be78dc4e","fromSide":"bottom","toNode":"a6afded3c1bcf43b","toSide":"top","color":"3"},
		{"id":"59b49a83e43c4e18","fromNode":"062f859f722c5e72","fromSide":"top","toNode":"0bd9e40011791242","toSide":"right","color":"3"},
		{"id":"463476a586b712a7","fromNode":"c5952d581e682572","fromSide":"bottom","toNode":"0e801b60be78dc4e","toSide":"right","color":"3"},
		{"id":"8b5cf533d6e11e8d","fromNode":"35c8e7cf83a5c5a8","fromSide":"left","toNode":"0e801b60be78dc4e","toSide":"right","color":"3"},
		{"id":"3d52f785fb4075ac","fromNode":"4082ae1a597e9bfa","fromSide":"left","toNode":"35c8e7cf83a5c5a8","toSide":"right","color":"3"},
		{"id":"48fd8951f1aafe77","fromNode":"7851cf57a7271a20","fromSide":"bottom","toNode":"58abfdf511c6185c","toSide":"top","color":"3"}
	]
}