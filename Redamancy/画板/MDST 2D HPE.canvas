{
	"nodes":[
		{"id":"f0665dfad8ca66d0","type":"text","text":"MDST: 2D Human Pose Estimation for SISO\nUWB Radar based on Micro-Doppler Signature\nvia Cascade and Parallel Swin Transformer","x":-400,"y":-260,"width":420,"height":60,"color":"4"},
		{"id":"773afe2914dc1b6e","type":"text","text":"1.数据采集和预处理\n2.MD签名的提取与特征嵌入\n3.微多普勒Swin Transformer网络（MDST）的构建\n4.倒特征金字塔网络（IFPN）的集成\n5.解码器模块和姿态估计","x":-420,"y":-180,"width":460,"height":160,"color":"4"},
		{"id":"425888f4dfeaac90","type":"file","file":"图片/Pasted image 20240909201243.png","x":-860,"y":20,"width":399,"height":254,"color":"1"},
		{"id":"3f55f939518b09f5","type":"text","text":"### **Fast Time 和 Slow Time 的定义以及回波图像的意义**\n- **Fast Time（快速时间）**：指的是雷达信号在一次脉冲周期内的采样时间。因此，Fast Time轴通常用于表示距离，因为传播时间与目标距离直接相关。\n- **Slow Time（慢速时间）**：指的是多个脉冲周期之间的时间采样。因此，Slow Time轴用于观察目标的运动特征，特别是其多普勒效应（速度信息）。\n- **横轴（Slow Time）表示某一个时间点**\n- **纵轴（Fast Time）表示某一个距离**\n- **交叉点表示某一个时间点特定距离的信号强度**","x":-860,"y":300,"width":400,"height":420,"color":"1"},
		{"id":"1ed0fd131c5a42d5","type":"file","file":"图片/Pasted image 20240909202734.png","x":-440,"y":20,"width":399,"height":252,"color":"1"},
		{"id":"b9f430f9ea61bdfc","type":"text","text":"1. **横轴（Doppler）**：横轴代表多普勒频率（Doppler Frequency），表示目标的相对速度。频率越高，意味着目标的相对速度越大。多普勒频率的变化反映了目标的运动速度（向雷达靠近或远离）。\n2. **纵轴（Range）**：纵轴表示距离（Range），通过快速时间（Fast Time）上的采样数据经过FFT转换得到。轴上的每一个点表示雷达回波信号在某个特定距离上的强度。\n3. **颜色表示信号强度（Amplitude）**：图中的颜色表示信号的幅度（或能量）。颜色越亮（如黄色和绿色），代表在该距离和多普勒频率组合下的信号强度越高。这通常意味着在该位置上存在显著的目标反射。","x":-440,"y":300,"width":400,"height":420,"color":"1"},
		{"id":"025d29f801972ef3","type":"file","file":"图片/Pasted image 20240909203400.png","x":-20,"y":20,"width":399,"height":249,"color":"1"},
		{"id":"c06368f612b47191","type":"text","text":"\n1. **对每个多普勒频率单元（Doppler Bin）进行累加**：在生成多普勒频谱图时，我们沿着距离维度（Range）方向进行累加。也就是说，对于每个多普勒频率单元（Doppler Bin），将该频率下所有距离（Range）的信号强度进行求和。换句话说，对于图中的每一个垂直的多普勒频率位置（例如`Doppler = 0`），我们会将从`Range = -100`到`Range = 100`范围内所有点的信号强度相加。这个过程在每个多普勒频率位置上都重复进行。\n2. **生成多普勒频谱图（Doppler Spectrum）**：结果是一个一维的图像：横轴是多普勒频率单元（Doppler Bin），纵轴是累积的信号强度（Summed Energy）。这个图像显示了在每个多普勒频率上所有距离上的总信号能量。","x":-20,"y":300,"width":400,"height":460,"color":"1"},
		{"id":"b1704cce4a516930","type":"file","file":"图片/Pasted image 20240909204013.png","x":400,"y":20,"width":385,"height":249,"color":"1"},
		{"id":"66b0b5416d66f693","type":"text","text":"要是只是为了HPE，为什么要有骨架重建的步骤，直接由动作标签训练","x":240,"y":-440,"width":380,"height":180},
		{"id":"31860e2c9b1d4d25","type":"file","file":"图片/Pasted image 20240910163656.png","x":1020,"y":-350,"width":360,"height":531,"color":"#21f505"},
		{"id":"e65d60691c757f69","type":"file","file":"图片/Pasted image 20240910163746.png","x":1020,"y":188,"width":360,"height":81,"color":"#21f505"},
		{"id":"7df531255579ef99","type":"file","file":"图片/Pasted image 20240910163811.png","x":1020,"y":280,"width":358,"height":65,"color":"#21f505"},
		{"id":"49a7c546c506ea93","type":"file","file":"图片/Pasted image 20240910202811.png","x":1020,"y":760,"width":514,"height":160,"color":"4"},
		{"id":"cf05d947002cee17","type":"file","file":"图片/Pasted image 20240910203034.png","x":1020,"y":940,"width":513,"height":236,"color":"4"},
		{"id":"b96cbe8b941203ea","type":"file","file":"图片/Pasted image 20240911101918.png","x":1020,"y":1200,"width":514,"height":286,"color":"4"},
		{"id":"531919b3cfb9c393","type":"file","file":"图片/Pasted image 20240911101942.png","x":1020,"y":1500,"width":513,"height":151,"color":"4"},
		{"id":"f0fc900ff5f33199","type":"text","text":"#### Swin Transformer\nSwin Transformer 在 ViT（Vision Transformer）的基础上进行了创新\n**分层架构**：Swin Transformer 构建了一个分层的特征表示结构。与 ViT 的单一低分辨率特征图不同，Swin Transformer 从较小的图像块开始，通过在更深的层次中逐步合并邻近的图像块，构建了一个多尺度的特征图。\n**基于移动窗口的自注意力机制**：ViT 的自注意力机制是全局的，会计算一个标记与所有其他标记之间的关系，导致计算复杂度随标记数量呈二次增长。Swin Transformer 引入了基于窗口的自注意力计算方法，将图像划分为不重叠的局部窗口，在每个窗口内计算自注意力，这使得计算复杂度相对于输入图像大小为线性。\n**移动窗口机制**：为了解决窗口自注意力模块在窗口之间缺乏连接的问题，Swin Transformer 提出了移动窗口分区的策略。在连续的 Swin Transformer 块之间切换窗口分区配置，使得跨窗口的连接更加有效。","x":1640,"y":920,"width":400,"height":560,"color":"4"},
		{"id":"833cbdffd98b9ca8","type":"text","text":"#### Transformer\n自注意力机制（Self-Attention）：自注意力机制的确是让网络自己学习序列中每个词与其他词的关联强度。查询（Query, Q）、键（Key, K）和值（Value, V）。\n计算相似度分数![[Pasted image 20240910164522.png]]。\n缩放（Scaled Dot-Product Attention）![[Pasted image 20240910164627.png]]。\n多头注意力机制（Multi-Head Attention）：使用多个QKV。\n","x":1470,"y":-259,"width":500,"height":350,"color":"#21f505"},
		{"id":"4933b0139e9a06d4","type":"file","file":"图片/Pasted image 20240910190109.png","x":1020,"y":426,"width":400,"height":218,"color":"4"},
		{"id":"a8a7f3e6a2bb0e49","type":"text","text":"#### Vit Transformer\n为什么Transformer可以用于图像任务：**将图像视为一系列图块**：与卷积神经网络（CNN）在像素网格上操作不同，ViT将图像看作一系列的图块（patches）。首先将输入图像划分为固定大小的图块，每个图块会被展平（flatten）并通过线性投影映射到一个高维特征空间。为了执行图像分类任务，ViT在输入序列的开头加入一个可学习的分类标记（[CLS] token）。经过Transformer编码器处理后，这个分类标记的输出被用作图像的全局表示。最终使用一个多层感知器（MLP）将其映射到类别空间来预测图像类别。","x":1500,"y":345,"width":440,"height":380,"color":"4"}
	],
	"edges":[
		{"id":"1ce7334e2a14f3a4","fromNode":"f0665dfad8ca66d0","fromSide":"bottom","toNode":"773afe2914dc1b6e","toSide":"top"},
		{"id":"c1fbc34a757e7f76","fromNode":"425888f4dfeaac90","fromSide":"bottom","toNode":"3f55f939518b09f5","toSide":"top"},
		{"id":"abef3f1f6562fd01","fromNode":"773afe2914dc1b6e","fromSide":"left","toNode":"425888f4dfeaac90","toSide":"top"},
		{"id":"65b453daf52acb37","fromNode":"425888f4dfeaac90","fromSide":"right","toNode":"1ed0fd131c5a42d5","toSide":"left"},
		{"id":"bf97e7e3f5cedbba","fromNode":"1ed0fd131c5a42d5","fromSide":"bottom","toNode":"b9f430f9ea61bdfc","toSide":"top"},
		{"id":"f20079467e123b36","fromNode":"025d29f801972ef3","fromSide":"bottom","toNode":"c06368f612b47191","toSide":"top"},
		{"id":"d0dfaecb2b4d3d3a","fromNode":"1ed0fd131c5a42d5","fromSide":"right","toNode":"025d29f801972ef3","toSide":"left"},
		{"id":"350c66051980f31b","fromNode":"025d29f801972ef3","fromSide":"right","toNode":"b1704cce4a516930","toSide":"left"},
		{"id":"e6192fc5d934ca8e","fromNode":"c06368f612b47191","fromSide":"right","toNode":"b1704cce4a516930","toSide":"bottom"},
		{"id":"297600d1e3374d22","fromNode":"4933b0139e9a06d4","fromSide":"right","toNode":"a8a7f3e6a2bb0e49","toSide":"left"},
		{"id":"d3968e1118aac4bc","fromNode":"31860e2c9b1d4d25","fromSide":"right","toNode":"833cbdffd98b9ca8","toSide":"left"},
		{"id":"d6e8cdcc9aaf9e0c","fromNode":"e65d60691c757f69","fromSide":"right","toNode":"833cbdffd98b9ca8","toSide":"bottom"},
		{"id":"ba3fb4a9610c5671","fromNode":"7df531255579ef99","fromSide":"right","toNode":"833cbdffd98b9ca8","toSide":"bottom"},
		{"id":"aca4c868af16eb19","fromNode":"49a7c546c506ea93","fromSide":"right","toNode":"f0fc900ff5f33199","toSide":"left"},
		{"id":"50c0049e77bfb272","fromNode":"cf05d947002cee17","fromSide":"right","toNode":"f0fc900ff5f33199","toSide":"left"},
		{"id":"ed08805f5be98b6e","fromNode":"b96cbe8b941203ea","fromSide":"right","toNode":"f0fc900ff5f33199","toSide":"left"},
		{"id":"5444b9c2290abd23","fromNode":"531919b3cfb9c393","fromSide":"right","toNode":"f0fc900ff5f33199","toSide":"left"}
	]
}