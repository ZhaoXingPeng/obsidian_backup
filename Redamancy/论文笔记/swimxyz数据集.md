Fiche G, Sevestre V, Gonzalez-Barral C, et al. SwimXYZ: A large-scale dataset of synthetic swimming motions and videos[C]//Proceedings of the 16th ACM SIGGRAPH Conference on Motion, Interaction and Games. 2023: 1-7.

![[Pasted image 20250319150948.png]]
![[sample.mp4]]
![[Pasted image 20250319151057.png]]
 **SwimXYZ** 的大型合成游泳动作和视频数据集，旨在推动游泳运动中基于计算机视觉的动作捕捉技术的发展。论文讨论了传统动作捕捉系统的局限性（昂贵且复杂，尤其在水下环境中），以及现有计算机视觉方法在游泳场景中的不足，主要归因于缺乏标注的游泳视频数据集。SwimXYZ 通过提供合成数据来填补这一空白，包含大量带有地面真实（ground truth）标签的游泳视频和动作序列，适用于姿势估计和动作分析等任务。

1. **SwimXYZ 数据集组成**：
   - **视频数据**：包含 11,520 个合成单目视频，总计 340 万帧，带有 2D 和 3D 关节的地面真实标签。
   - **动作序列**：包含 240 个游泳动作序列，以 SMPL（Skinned Multi-Person Linear）参数格式存储。
   - 数据涵盖四种泳姿（仰泳、蛙泳、蝶泳、自由泳），并具有多样化的相机角度、人物外观、水面效果和光照条件。

---

### **数据集的标签和数据组织方式**

#### **1. 数据集组成**
SwimXYZ 包含两部分主要数据：
- **视频数据集**：
  - 数量：11,520 个视频。
  - 总帧数：340 万帧。
  - 每个视频时长 5 秒，帧率 60 FPS（每视频 300 帧）。
- **动作序列数据集**：
  - 数量：240 个游泳动作序列（每种泳姿 60 个）。
  - 格式：SMPL 参数。
#### **2. 标签类型**
- **视频数据的标签**：
  - **2D 关节**：每个帧标注了 2D 关节位置，采用以下三种格式：
    - **COCO17**：17 个关节（如头部、肩膀、肘部等）。
    - **COCO25**：25 个关节（扩展版，包含更多细节）。
    - **Base**：48 个关节（更详细的骨骼结构）。
  - **3D 关节**：每个帧提供 3D 关节位置，与 2D 标签对应。
  - **参考框架**：关节坐标在两种参考系中提供：
    - 全局坐标系。
    - 以泳者骨盆为中心的局部坐标系。
- **动作序列的标签**：
  - 以 SMPL 格式存储，包含：
    - **身体形状参数 (β)**：16 个参数，描述身体细节。
    - **姿势参数 (θ)**：72 个参数，描述关节角度。
    - **全局平移参数 (γ)**：3 个参数，描述位置。
    - 输出包括 21 个 3D 关节位置和 6890 个顶点的 3D 三角形网格。
#### **3. 数据组织方式**
- **视频数据库结构**（见论文图 3）：
![[Pasted image 20250319151233.png]]
  - 数据通过参数网格生成，避免重复，每个视频对应一组唯一参数组合。
  - **变化维度**包括：
    - **泳姿**：仰泳、蛙泳、蝶泳、自由泳。
    - **相机视角**：前视、俯视、水下侧视、水上侧视、水面侧视。
    - **动作速度**：随机速度。
    - **起始位置**：泳池中的随机位置。
    - **水面效果**：颜色、透明度、折射、反射、波浪等约 50 个参数（12 个可调）。
    - **光照**：不同时间段的光源和颜色。
    - **人物外观**：肌肉量、肤色、湿润效果等。
    - **粒子效果**：飞溅和泡沫，随泳姿和速度变化。
----
## 最近使用过swimxyz数据集的文献：

Al-Majnoni A, Al-Sahli J, Al-Ahmady D, et al. Moar: A Swimmer Motion Swimming Style Identification Model using Deep Learning[J]. Engineering, Technology & Applied Science Research, 2025, 15(1): 19295-19302.
旨在同时识别游泳者的泳姿（freestyle、backstroke、breaststroke、butterfly）和检测泳姿中的技术缺陷（flaws）。以下是文章的主要内容和对 SwimXYZ 数据集的使用方式：
1. **研究目标**：
   - 开发一个能够同时识别四种主要泳姿（自由泳、仰泳、蛙泳、蝶泳）并检测泳姿中错误动作的计算机视觉模型。解决传统动作捕捉系统成本高、受限，以及现有计算机视觉方法缺乏标注游泳缺陷数据的问题。
2. **方法**：
   - **数据集整合**：研究团队收集了游泳动作缺陷（flaws）的数据，并将其与公开的 SwimXYZ 数据集整合，用于训练模型。
   - **模型选择**：使用了 YOLO（You Only Look Once）系列目标检测模型，包括 YOLOv5n、YOLOv5s、YOLOv8n 和 YOLOv8s，进行泳姿和缺陷的检测。
3. **创新点**：
   - 以往的研究多集中于泳姿分类，较少关注动作缺陷的检测。这项研究通过引入 Swim-Mistakes 数据集填补了这一空白。
4. **数据整合**：
   - 将清洗后的 SwimXYZ 数据集与研究团队收集的游泳缺陷数据（称为 Swim-Mistakes 数据集）整合。
   - 整合后的数据集用于训练 YOLO 模型，使其能够同时学习泳姿分类和缺陷检测。
![[Pasted image 20250321173301.png]]
---
## 溺水检测数据集
[Wang-Kaikai/drowning-detection-dataset: This is a self-made dataset designed for drowning detection.](https://github.com/Wang-Kaikai/drowning-detection-dataset/tree/main)

![[Pasted image 20250321192702.png]]
![[Pasted image 20250321192730.png]]
![[Pasted image 20250321192808.png]]
YOLO标注
在溺水检测数据集中，标签文件通常用于描述图像或视频帧中目标对象的类别和位置信息。
例子“1 0.7113095238095237 0.5089285714285714 0.0900297619047619 0.17658730158730157”是一个常见的标注格式，很可能是基于YOLO（You Only Look Once）。
这种格式通常包含以下五个数字，每个数字有特定的含义：
### 标签的含义
1. **第一个数字（1）**：类别ID（Class ID）
    - 表示目标对象的类别。在溺水检测数据集中，通常会有多个类别，例如“溺水”（drowning）和“正常游泳”（swimming）。这里“1”可能代表“溺水”类别，而“0”可能代表“正常游泳”或其他背景类别。
2. **第二个数字（0.7113095238095237）**：边界框中心点的x坐标（x_center）
    - 表示目标对象边界框中心的x坐标，归一化为图像宽度的比例（0到1之间）。
3. **第三个数字（0.5089285714285714）**：边界框中心点的y坐标（y_center）
    - 表示目标对象边界框中心的y坐标，归一化为图像高度的比例（0到1之间）。
4. **第四个数字（0.0900297619047619）**：边界框宽度（width）
    - 表示边界框的宽度，归一化为图像宽度的比例（0到1之间）。
5. **第五个数字（0.17658730158730157）**：边界框高度（height）
    - 表示边界框的高度，归一化为图像高度的比例（0到1之间）。
----

## 其它领域的应用
Delhaye E, Bouvet A, Nicolas G, et al. Automatic swimming activity recognition and lap time assessment based on a single IMU: a deep learning approach[J]. Sensors, 2022, 22(15): 5786.
它主要研究了如何利用单个惯性测量单元（IMU）和深度学习技术，对游泳活动进行自动识别和圈时评估。
- **主要目标**：开发一个基于单个IMU的深度学习模型，用于分析游泳活动，识别八种不同的游泳相关动作（包括四种泳姿和非游泳阶段），并在不同速度下实现高精度分类。
- **次要目标**：直接从分类器中计算圈时（Lap Time, LT），并通过视频标准验证其准确性。
- **数据采集**：
  - 参与者：35名游泳者（11女24男，年龄23.23±8.85岁，游泳经验8.88±2.95年），水平从娱乐到二级联赛不等。
  - 设备：一个防水IMU（含3D加速度计和陀螺仪，采样率280Hz），固定在游泳者的骶骨位置。
  - 实验环境：室内25米泳池，使用三台摄像头（30Hz）作为视频金标准同步验证。
  - 协议：包括3次100米混合泳和4次单泳姿100米，速度从低到最大变化，增加动作变异性。
- **数据处理与模型**：
  - **预处理**：IMU数据通过巴特沃斯低通滤波（10Hz）并降采样至50Hz，标准化后输入模型。
  - **分割**：使用滑动窗口（1.8秒，90帧）分割时间序列数据。
  - **模型架构**：采用双向长短期记忆网络（Bi-LSTM），包括多层神经网络结构，使用TensorFlow和Keras实现，训练10个epoch，优化器为ADAM，损失函数为稀疏分类交叉熵。
  - **分类目标**：八个类别——壁推（Wallpush）、水下（Underwater）、蝶泳（Butterfly）、仰泳（Backstroke）、蛙泳（Breaststroke）、自由泳（Frontcrawl）、转身（Turn）、休息（Rest）。
  - **验证**：使用持一法（Holdout-Subject Cross-Validation）确保模型泛化能力。
- **活动识别**：
  - 总体F1分数达到0.96，时间精度为0.02秒。
  - 四种泳姿的F1分数在0.93-0.99之间，非游泳阶段（如转身和水下）稍低，但仍具高精度。
  - 短时动作（如壁推，F1=0.28）因数据较少识别较差，但不影响整体应用。
- **圈时评估**：
  - IMU计算的圈时（LT IMU）与视频标准（LT CAM）的平均绝对百分比误差（MAPE）分别为：起始圈1.15%、中间圈1%、结束圈4.07%，总体误差1.77±1.82%（约0.42±0.43秒）。
  - 与手动秒表（LT MAN）相比，LT IMU误差略高但更自动化，TEM为0.60秒。
- **创新点**：
  - 首次利用深度学习和单个IMU实现八类游泳活动的精细分类，覆盖多种速度和水平。
  - 高时间精度（0.02秒）支持实时监控，优于传统基于阈值或特征工程的方法。
  - 数据集具有高异质性（inter-和intra-swimmer variability），增强模型泛化能力。
- **与其他研究的比较**：
  - 相较传统信号处理（精度高达100%但泛化差）和经典机器学习（F1约0.97-0.99），本研究在复杂场景下表现更稳健。
  - 圈时误差（0.06±0.60秒）优于之前研究（如0.72±0.26秒）。
----
Shatnawi M, Albreiki F, Alkhoori A, et al. Deep learning and vision-based early drowning detection[J]. Information, 2023, 14(1): 52.
它提出了一种基于计算机视觉和深度学习的早期溺水检测方法，旨在通过分析游泳池中的图像数据，自动识别溺水事件，以提高游泳者的安全性，特别是儿童。以下是论文内容的详细概述：
- **数据集**：
  - 数据来源：通过谷歌搜索引擎收集200张图像，分为两类——溺水（drowning）和正常游泳（swimming），每类100张。
  - 数据划分：50%（100张，50溺水+50游泳）用于训练和验证（训练70%，验证30%），另50%（100张）用于测试。
  - 数据增强：因数据量有限，使用旋转（角度范围：SqueezeNet为-60°至60°，其他模型为-45°至45°）和随机缩放（1-2倍）增加数据多样性，防止过拟合。
- **模型**：
  - 选用五种预训练卷积神经网络（CNN）：SqueezeNet、GoogleNet、AlexNet、ShuffleNet和ResNet50。
  - 调整网络参数：将卷积层滤波器大小改为1×1，滤波器数量改为2（匹配两类输出），分类层适配溺水/游泳标签。
  - 训练设置：初始学习率0.0001，最大迭代次数和epoch数因模型而异（15-60），批大小11，验证频率5次迭代，使用MATLAB深度学习工具箱在单CPU（1.8GHz，8GB内存）上运行。
- **评估指标**：
  - 包括准确率（Accuracy, Ac）、召回率（Recall, R）、特异性（Specificity, Sp）、精确度（Precision, Pr）、F1分数（F1）和马修斯相关系数（MCC），基于真阳性（TP）、真阴性（TN）、假阳性（FP）和假阴性（FN）计算。
- **训练与验证**：
  - SqueezeNet：20 epoch，26秒，验证准确率100%。
  - ResNet50：20 epoch，2分33秒，验证准确率100%。
  - ShuffleNet：18 epoch，7分18秒，验证准确率100%。
  - AlexNet：15 epoch，1分5秒，验证准确率91.67%。
  - GoogleNet：60 epoch，3分36秒，验证准确率91.67%。
  - SqueezeNet训练时间最短，ResNet50兼顾高准确率和合理训练时间。 
![[Pasted image 20250321185721.png]]
----
